{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding import pipeline as pipe\n",
    "import pickle\n",
    "from embedding.embedding_base import EmbeddingBase\n",
    "import pandas as pd\n",
    "from embedding import sentence_embedding\n",
    "from classifier import recurrent_NN as rec\n",
    "import numpy as np\n",
    "from classifier import Adaboost_classi as classy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different preprocessing techniques performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try first with Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada1 = classy.Adaboost_classi(embedding_dimension=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We fit the model on each training matrix we created. For each different pre processing technique, we fit the model on the training matrix obtained using the summation of the embeddings (1) and on the one using their concatenation (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 : Negation marking + lemmatization + replacement, vocab: 10 words min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_neg_mark_10_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_neg_mark_10_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "x = arr1[:,:-1]\n",
    "y = arr1[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "Training model\n",
      "[0.74505  0.73265  0.7348   0.737075 0.7299  ]\n"
     ]
    }
   ],
   "source": [
    "ada1.build()\n",
    "ada1.train(x,y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "Training model\n",
      "[0.68045  0.665375 0.658175 0.651375 0.651825]\n"
     ]
    }
   ],
   "source": [
    "arr0 = arr0['arr_0']\n",
    "x = arr0[:,:-1]\n",
    "y = arr0[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2 : full vocabulary, 10 words min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_10_full_12656_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_10_full_12656_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "Training model\n",
      "[0.676525 0.664375 0.649675 0.64375  0.64265 ]\n",
      "Building model.\n",
      "Training model\n",
      "[0.744575 0.738725 0.7344   0.727225 0.728475]\n"
     ]
    }
   ],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_10_full_12656_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_10_full_12656_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']\n",
    "x = arr0[:,:-1]\n",
    "y = arr0[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)\n",
    "x = arr1[:,:-1]\n",
    "y = arr1[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3 : full vocabulary, 5 words min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "Training model\n",
      "[0.67975  0.6726   0.665075 0.6458   0.651375]\n",
      "Building model.\n",
      "Training model\n",
      "[0.742125 0.740225 0.7326   0.73465  0.72855 ]\n"
     ]
    }
   ],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_full_21175_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_full_21175_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']\n",
    "x = arr0[:,:-1]\n",
    "y = arr0[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)\n",
    "x = arr1[:,:-1]\n",
    "y = arr1[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4 : lemmatized, 5 words min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "Training model\n",
      "[0.68185  0.6731   0.659225 0.65675  0.64905 ]\n",
      "Building model.\n",
      "Training model\n",
      "[0.747275 0.7373   0.732575 0.7278   0.728425]\n"
     ]
    }
   ],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_lemm_18082_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_lemm_18082_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']\n",
    "x = arr0[:,:-1]\n",
    "y = arr0[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)\n",
    "x = arr1[:,:-1]\n",
    "y = arr1[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 5 : lemmatized and replacement, 10 words min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "Training model\n",
      "[0.67565  0.66215  0.6506   0.651775 0.648875]\n",
      "Building model.\n",
      "Training model\n",
      "[0.653925 0.6729   0.67355  0.6757   0.664675]\n"
     ]
    }
   ],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_lemm_rep_10_10810_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_lemm_rep_10_10810_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']\n",
    "x = arr0[:,:-1]\n",
    "y = arr0[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)\n",
    "x = arr1[:,:-1]\n",
    "y = arr1[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 6: lemmatized with stop words, 5 words min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "Training model\n",
      "[0.6801  0.67535 0.66295 0.6671  0.6518 ]\n",
      "Building model.\n",
      "Training model\n",
      "[0.7465   0.73465  0.734775 0.72555  0.734675]\n"
     ]
    }
   ],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_lemm_stop_17543_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_lemm_stop_17543_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']\n",
    "x = arr0[:,:-1]\n",
    "y = arr0[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)\n",
    "x = arr1[:,:-1]\n",
    "y = arr1[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 6: negation_marking + lemmatized + replacement with stop words, 5 words min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "Training model\n",
      "[0.689825 0.67745  0.667875 0.659575 0.660225]\n",
      "Building model.\n",
      "Training model\n",
      "[0.739875 0.731225 0.7299   0.740125 0.730275]\n"
     ]
    }
   ],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_neg_mark_5_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_neg_mark_5_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']\n",
    "x = arr0[:,:-1]\n",
    "y = arr0[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)\n",
    "x = arr1[:,:-1]\n",
    "y = arr1[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model.\n",
      "Training model\n",
      "[0.689825 0.67745  0.667875 0.659575 0.660225]\n",
      "Building model.\n",
      "Training model\n",
      "[0.74505  0.73265  0.7348   0.737075 0.7299  ]\n"
     ]
    }
   ],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_neg_mark_10_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_neg_mark_10_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']\n",
    "x = arr0[:,:-1]\n",
    "y = arr0[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)\n",
    "x = arr1[:,:-1]\n",
    "y = arr1[:,-1]\n",
    "ada1.build()\n",
    "ada1.train(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_neg_mark_10_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_neg_mark_10_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Matrix Negation Marking 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.003153</td>\n",
       "      <td>0.059375</td>\n",
       "      <td>1.176305</td>\n",
       "      <td>3.099393</td>\n",
       "      <td>-1.480270</td>\n",
       "      <td>4.261483</td>\n",
       "      <td>0.943238</td>\n",
       "      <td>4.699919</td>\n",
       "      <td>-3.448722</td>\n",
       "      <td>-0.142886</td>\n",
       "      <td>...</td>\n",
       "      <td>1.045596</td>\n",
       "      <td>-0.496502</td>\n",
       "      <td>-2.010463</td>\n",
       "      <td>-0.434142</td>\n",
       "      <td>-1.273661</td>\n",
       "      <td>-0.963589</td>\n",
       "      <td>0.605833</td>\n",
       "      <td>-6.403092</td>\n",
       "      <td>-0.199765</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.321177</td>\n",
       "      <td>1.825059</td>\n",
       "      <td>-0.769256</td>\n",
       "      <td>0.178490</td>\n",
       "      <td>-0.718400</td>\n",
       "      <td>1.207151</td>\n",
       "      <td>-0.084270</td>\n",
       "      <td>1.154780</td>\n",
       "      <td>-1.641488</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>...</td>\n",
       "      <td>1.280981</td>\n",
       "      <td>0.965464</td>\n",
       "      <td>-0.973246</td>\n",
       "      <td>-1.519586</td>\n",
       "      <td>0.282107</td>\n",
       "      <td>-1.801000</td>\n",
       "      <td>1.383495</td>\n",
       "      <td>-1.647566</td>\n",
       "      <td>1.779701</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.734488</td>\n",
       "      <td>3.936739</td>\n",
       "      <td>2.391126</td>\n",
       "      <td>0.460451</td>\n",
       "      <td>-0.578238</td>\n",
       "      <td>2.692345</td>\n",
       "      <td>-1.616632</td>\n",
       "      <td>-0.074683</td>\n",
       "      <td>-1.271235</td>\n",
       "      <td>2.182798</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.101593</td>\n",
       "      <td>-0.507666</td>\n",
       "      <td>-2.275459</td>\n",
       "      <td>-0.834760</td>\n",
       "      <td>-1.990884</td>\n",
       "      <td>-1.445940</td>\n",
       "      <td>-1.416654</td>\n",
       "      <td>-2.017740</td>\n",
       "      <td>1.759486</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135106</td>\n",
       "      <td>3.985985</td>\n",
       "      <td>0.389060</td>\n",
       "      <td>1.600472</td>\n",
       "      <td>-2.463097</td>\n",
       "      <td>3.008654</td>\n",
       "      <td>-0.024798</td>\n",
       "      <td>-0.037095</td>\n",
       "      <td>-1.822041</td>\n",
       "      <td>-0.272107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338051</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>-2.601778</td>\n",
       "      <td>-1.545038</td>\n",
       "      <td>-2.024183</td>\n",
       "      <td>-1.997911</td>\n",
       "      <td>0.781345</td>\n",
       "      <td>-1.887818</td>\n",
       "      <td>2.361278</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.613785</td>\n",
       "      <td>5.386377</td>\n",
       "      <td>0.637572</td>\n",
       "      <td>2.182370</td>\n",
       "      <td>-0.739840</td>\n",
       "      <td>5.847832</td>\n",
       "      <td>0.362601</td>\n",
       "      <td>2.185732</td>\n",
       "      <td>-1.529609</td>\n",
       "      <td>0.928507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032873</td>\n",
       "      <td>-0.966383</td>\n",
       "      <td>-2.135091</td>\n",
       "      <td>-1.212612</td>\n",
       "      <td>-1.279975</td>\n",
       "      <td>-2.457171</td>\n",
       "      <td>-1.297063</td>\n",
       "      <td>-3.704950</td>\n",
       "      <td>1.203137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2.161770</td>\n",
       "      <td>2.376540</td>\n",
       "      <td>0.549252</td>\n",
       "      <td>0.757603</td>\n",
       "      <td>-0.539783</td>\n",
       "      <td>1.224371</td>\n",
       "      <td>-1.090748</td>\n",
       "      <td>1.117586</td>\n",
       "      <td>-0.951006</td>\n",
       "      <td>-0.808506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917931</td>\n",
       "      <td>0.326258</td>\n",
       "      <td>-1.303018</td>\n",
       "      <td>-1.055922</td>\n",
       "      <td>-1.285632</td>\n",
       "      <td>0.081401</td>\n",
       "      <td>-1.352616</td>\n",
       "      <td>-1.078003</td>\n",
       "      <td>1.330686</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>6.215346</td>\n",
       "      <td>5.332097</td>\n",
       "      <td>-0.474458</td>\n",
       "      <td>3.778277</td>\n",
       "      <td>-1.145942</td>\n",
       "      <td>7.949866</td>\n",
       "      <td>-2.926236</td>\n",
       "      <td>2.767899</td>\n",
       "      <td>-4.679984</td>\n",
       "      <td>-0.992254</td>\n",
       "      <td>...</td>\n",
       "      <td>3.229219</td>\n",
       "      <td>0.043773</td>\n",
       "      <td>-2.247994</td>\n",
       "      <td>-3.709773</td>\n",
       "      <td>-3.846788</td>\n",
       "      <td>-5.735913</td>\n",
       "      <td>-0.529322</td>\n",
       "      <td>-3.589694</td>\n",
       "      <td>6.460107</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>3.411396</td>\n",
       "      <td>5.563155</td>\n",
       "      <td>-1.343509</td>\n",
       "      <td>2.165330</td>\n",
       "      <td>-0.979198</td>\n",
       "      <td>3.272943</td>\n",
       "      <td>-0.350629</td>\n",
       "      <td>1.206431</td>\n",
       "      <td>-4.226316</td>\n",
       "      <td>0.285101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397136</td>\n",
       "      <td>-1.104894</td>\n",
       "      <td>-1.889345</td>\n",
       "      <td>-1.682679</td>\n",
       "      <td>-2.705730</td>\n",
       "      <td>-3.166605</td>\n",
       "      <td>-1.643026</td>\n",
       "      <td>-3.306980</td>\n",
       "      <td>3.329864</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2.895358</td>\n",
       "      <td>3.510256</td>\n",
       "      <td>-0.086647</td>\n",
       "      <td>1.355704</td>\n",
       "      <td>-1.642892</td>\n",
       "      <td>3.898547</td>\n",
       "      <td>-1.836652</td>\n",
       "      <td>1.553336</td>\n",
       "      <td>-2.044370</td>\n",
       "      <td>-1.004196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.201145</td>\n",
       "      <td>-1.087625</td>\n",
       "      <td>-1.780723</td>\n",
       "      <td>-2.044479</td>\n",
       "      <td>-2.705108</td>\n",
       "      <td>-3.959178</td>\n",
       "      <td>0.660978</td>\n",
       "      <td>-2.665578</td>\n",
       "      <td>5.364046</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>4.218060</td>\n",
       "      <td>9.579492</td>\n",
       "      <td>1.227943</td>\n",
       "      <td>4.080159</td>\n",
       "      <td>-0.774645</td>\n",
       "      <td>5.737889</td>\n",
       "      <td>-1.520243</td>\n",
       "      <td>4.509464</td>\n",
       "      <td>-7.240996</td>\n",
       "      <td>-0.418048</td>\n",
       "      <td>...</td>\n",
       "      <td>1.202845</td>\n",
       "      <td>-0.797265</td>\n",
       "      <td>-5.795557</td>\n",
       "      <td>-3.640293</td>\n",
       "      <td>-4.994938</td>\n",
       "      <td>-1.735266</td>\n",
       "      <td>0.486415</td>\n",
       "      <td>-5.892075</td>\n",
       "      <td>6.767427</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0       2.003153  0.059375  1.176305  3.099393 -1.480270  4.261483  0.943238   \n",
       "1       1.321177  1.825059 -0.769256  0.178490 -0.718400  1.207151 -0.084270   \n",
       "2       2.734488  3.936739  2.391126  0.460451 -0.578238  2.692345 -1.616632   \n",
       "3       0.135106  3.985985  0.389060  1.600472 -2.463097  3.008654 -0.024798   \n",
       "4       1.613785  5.386377  0.637572  2.182370 -0.739840  5.847832  0.362601   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995  2.161770  2.376540  0.549252  0.757603 -0.539783  1.224371 -1.090748   \n",
       "199996  6.215346  5.332097 -0.474458  3.778277 -1.145942  7.949866 -2.926236   \n",
       "199997  3.411396  5.563155 -1.343509  2.165330 -0.979198  3.272943 -0.350629   \n",
       "199998  2.895358  3.510256 -0.086647  1.355704 -1.642892  3.898547 -1.836652   \n",
       "199999  4.218060  9.579492  1.227943  4.080159 -0.774645  5.737889 -1.520243   \n",
       "\n",
       "             7         8         9    ...       191       192       193  \\\n",
       "0       4.699919 -3.448722 -0.142886  ...  1.045596 -0.496502 -2.010463   \n",
       "1       1.154780 -1.641488  0.937143  ...  1.280981  0.965464 -0.973246   \n",
       "2      -0.074683 -1.271235  2.182798  ... -1.101593 -0.507666 -2.275459   \n",
       "3      -0.037095 -1.822041 -0.272107  ...  0.338051  0.004642 -2.601778   \n",
       "4       2.185732 -1.529609  0.928507  ... -0.032873 -0.966383 -2.135091   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "199995  1.117586 -0.951006 -0.808506  ...  0.917931  0.326258 -1.303018   \n",
       "199996  2.767899 -4.679984 -0.992254  ...  3.229219  0.043773 -2.247994   \n",
       "199997  1.206431 -4.226316  0.285101  ...  0.397136 -1.104894 -1.889345   \n",
       "199998  1.553336 -2.044370 -1.004196  ...  1.201145 -1.087625 -1.780723   \n",
       "199999  4.509464 -7.240996 -0.418048  ...  1.202845 -0.797265 -5.795557   \n",
       "\n",
       "             194       195       196       197       198       199  200  \n",
       "0      -0.434142 -1.273661 -0.963589  0.605833 -6.403092 -0.199765  0.0  \n",
       "1      -1.519586  0.282107 -1.801000  1.383495 -1.647566  1.779701  0.0  \n",
       "2      -0.834760 -1.990884 -1.445940 -1.416654 -2.017740  1.759486  0.0  \n",
       "3      -1.545038 -2.024183 -1.997911  0.781345 -1.887818  2.361278  0.0  \n",
       "4      -1.212612 -1.279975 -2.457171 -1.297063 -3.704950  1.203137  0.0  \n",
       "...          ...       ...       ...       ...       ...       ...  ...  \n",
       "199995 -1.055922 -1.285632  0.081401 -1.352616 -1.078003  1.330686  1.0  \n",
       "199996 -3.709773 -3.846788 -5.735913 -0.529322 -3.589694  6.460107  1.0  \n",
       "199997 -1.682679 -2.705730 -3.166605 -1.643026 -3.306980  3.329864  1.0  \n",
       "199998 -2.044479 -2.705108 -3.959178  0.660978 -2.665578  5.364046  1.0  \n",
       "199999 -3.640293 -4.994938 -1.735266  0.486415 -5.892075  6.767427  1.0  \n",
       "\n",
       "[200000 rows x 201 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Matrix lemmatization and replacement 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.364442</td>\n",
       "      <td>2.711838</td>\n",
       "      <td>-1.973383</td>\n",
       "      <td>1.721517</td>\n",
       "      <td>-2.512698</td>\n",
       "      <td>1.555344</td>\n",
       "      <td>4.958007</td>\n",
       "      <td>2.567133</td>\n",
       "      <td>-0.175546</td>\n",
       "      <td>1.446702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240848</td>\n",
       "      <td>0.313587</td>\n",
       "      <td>0.242469</td>\n",
       "      <td>-1.799657</td>\n",
       "      <td>1.713323</td>\n",
       "      <td>2.557487</td>\n",
       "      <td>-0.093983</td>\n",
       "      <td>-0.900870</td>\n",
       "      <td>1.692980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.547912</td>\n",
       "      <td>0.561529</td>\n",
       "      <td>-1.754580</td>\n",
       "      <td>-1.130136</td>\n",
       "      <td>-0.304568</td>\n",
       "      <td>1.005415</td>\n",
       "      <td>1.183256</td>\n",
       "      <td>-0.033421</td>\n",
       "      <td>0.484009</td>\n",
       "      <td>-1.359124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.592055</td>\n",
       "      <td>-1.097049</td>\n",
       "      <td>-0.023258</td>\n",
       "      <td>-0.371026</td>\n",
       "      <td>1.504519</td>\n",
       "      <td>0.972150</td>\n",
       "      <td>-0.066232</td>\n",
       "      <td>-0.605402</td>\n",
       "      <td>0.266169</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.118670</td>\n",
       "      <td>3.334513</td>\n",
       "      <td>-0.103789</td>\n",
       "      <td>-1.211855</td>\n",
       "      <td>-1.564432</td>\n",
       "      <td>3.705067</td>\n",
       "      <td>4.505796</td>\n",
       "      <td>-0.094455</td>\n",
       "      <td>-1.155750</td>\n",
       "      <td>0.818007</td>\n",
       "      <td>...</td>\n",
       "      <td>2.897853</td>\n",
       "      <td>1.533973</td>\n",
       "      <td>0.941882</td>\n",
       "      <td>-1.207514</td>\n",
       "      <td>-0.646047</td>\n",
       "      <td>-0.057464</td>\n",
       "      <td>-0.920259</td>\n",
       "      <td>-1.355515</td>\n",
       "      <td>0.844375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966103</td>\n",
       "      <td>3.638089</td>\n",
       "      <td>-1.711699</td>\n",
       "      <td>-0.869258</td>\n",
       "      <td>-3.289789</td>\n",
       "      <td>1.429641</td>\n",
       "      <td>2.584887</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>-0.210630</td>\n",
       "      <td>1.007587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.681879</td>\n",
       "      <td>-1.759520</td>\n",
       "      <td>-0.232496</td>\n",
       "      <td>-1.399346</td>\n",
       "      <td>0.713252</td>\n",
       "      <td>-1.153311</td>\n",
       "      <td>1.075085</td>\n",
       "      <td>-3.261237</td>\n",
       "      <td>0.879324</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.182926</td>\n",
       "      <td>2.608265</td>\n",
       "      <td>-0.514734</td>\n",
       "      <td>1.175587</td>\n",
       "      <td>-1.764631</td>\n",
       "      <td>0.792961</td>\n",
       "      <td>1.357220</td>\n",
       "      <td>0.123349</td>\n",
       "      <td>0.940386</td>\n",
       "      <td>0.531076</td>\n",
       "      <td>...</td>\n",
       "      <td>1.554797</td>\n",
       "      <td>-1.125571</td>\n",
       "      <td>0.221238</td>\n",
       "      <td>-1.169966</td>\n",
       "      <td>0.047702</td>\n",
       "      <td>-0.031349</td>\n",
       "      <td>0.116110</td>\n",
       "      <td>-1.230358</td>\n",
       "      <td>-0.488179</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0.062834</td>\n",
       "      <td>0.941035</td>\n",
       "      <td>0.639358</td>\n",
       "      <td>-0.700971</td>\n",
       "      <td>0.334113</td>\n",
       "      <td>0.610259</td>\n",
       "      <td>1.520712</td>\n",
       "      <td>-0.267464</td>\n",
       "      <td>0.343965</td>\n",
       "      <td>-1.044237</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.614024</td>\n",
       "      <td>-0.304913</td>\n",
       "      <td>-0.652910</td>\n",
       "      <td>-0.083011</td>\n",
       "      <td>-0.182136</td>\n",
       "      <td>-0.164620</td>\n",
       "      <td>0.341852</td>\n",
       "      <td>-1.212167</td>\n",
       "      <td>0.772141</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>0.488083</td>\n",
       "      <td>3.639241</td>\n",
       "      <td>-5.607270</td>\n",
       "      <td>3.555391</td>\n",
       "      <td>-2.886949</td>\n",
       "      <td>5.040390</td>\n",
       "      <td>8.506230</td>\n",
       "      <td>-0.619971</td>\n",
       "      <td>-1.174315</td>\n",
       "      <td>1.858987</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.601829</td>\n",
       "      <td>-4.318220</td>\n",
       "      <td>1.902997</td>\n",
       "      <td>-1.239073</td>\n",
       "      <td>-2.094194</td>\n",
       "      <td>-4.741051</td>\n",
       "      <td>0.160564</td>\n",
       "      <td>-3.697052</td>\n",
       "      <td>0.132502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>1.364439</td>\n",
       "      <td>6.920882</td>\n",
       "      <td>-0.689313</td>\n",
       "      <td>-0.566676</td>\n",
       "      <td>-3.809954</td>\n",
       "      <td>1.903388</td>\n",
       "      <td>4.127519</td>\n",
       "      <td>0.413602</td>\n",
       "      <td>-2.244772</td>\n",
       "      <td>1.099213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965286</td>\n",
       "      <td>-2.060376</td>\n",
       "      <td>0.051719</td>\n",
       "      <td>-4.619251</td>\n",
       "      <td>0.388369</td>\n",
       "      <td>-3.389189</td>\n",
       "      <td>1.176797</td>\n",
       "      <td>-2.018846</td>\n",
       "      <td>-0.324313</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2.506945</td>\n",
       "      <td>4.622958</td>\n",
       "      <td>-1.796340</td>\n",
       "      <td>-0.925103</td>\n",
       "      <td>-0.625245</td>\n",
       "      <td>-0.357747</td>\n",
       "      <td>1.076692</td>\n",
       "      <td>1.051494</td>\n",
       "      <td>-1.053511</td>\n",
       "      <td>-0.798003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582595</td>\n",
       "      <td>-0.880470</td>\n",
       "      <td>-0.685185</td>\n",
       "      <td>-3.221213</td>\n",
       "      <td>1.341757</td>\n",
       "      <td>-2.525892</td>\n",
       "      <td>0.633955</td>\n",
       "      <td>-3.130941</td>\n",
       "      <td>1.439956</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0.594009</td>\n",
       "      <td>2.380545</td>\n",
       "      <td>-0.663650</td>\n",
       "      <td>0.199102</td>\n",
       "      <td>-0.279556</td>\n",
       "      <td>1.306124</td>\n",
       "      <td>6.850102</td>\n",
       "      <td>-2.002757</td>\n",
       "      <td>-1.981669</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>...</td>\n",
       "      <td>3.131499</td>\n",
       "      <td>-0.470769</td>\n",
       "      <td>0.746012</td>\n",
       "      <td>-1.574813</td>\n",
       "      <td>-0.227272</td>\n",
       "      <td>-0.050823</td>\n",
       "      <td>-2.548302</td>\n",
       "      <td>-2.000663</td>\n",
       "      <td>6.103354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0      -0.364442  2.711838 -1.973383  1.721517 -2.512698  1.555344  4.958007   \n",
       "1      -0.547912  0.561529 -1.754580 -1.130136 -0.304568  1.005415  1.183256   \n",
       "2       1.118670  3.334513 -0.103789 -1.211855 -1.564432  3.705067  4.505796   \n",
       "3       0.966103  3.638089 -1.711699 -0.869258 -3.289789  1.429641  2.584887   \n",
       "4      -0.182926  2.608265 -0.514734  1.175587 -1.764631  0.792961  1.357220   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995  0.062834  0.941035  0.639358 -0.700971  0.334113  0.610259  1.520712   \n",
       "199996  0.488083  3.639241 -5.607270  3.555391 -2.886949  5.040390  8.506230   \n",
       "199997  1.364439  6.920882 -0.689313 -0.566676 -3.809954  1.903388  4.127519   \n",
       "199998  2.506945  4.622958 -1.796340 -0.925103 -0.625245 -0.357747  1.076692   \n",
       "199999  0.594009  2.380545 -0.663650  0.199102 -0.279556  1.306124  6.850102   \n",
       "\n",
       "             7         8         9    ...       191       192       193  \\\n",
       "0       2.567133 -0.175546  1.446702  ... -0.240848  0.313587  0.242469   \n",
       "1      -0.033421  0.484009 -1.359124  ... -0.592055 -1.097049 -0.023258   \n",
       "2      -0.094455 -1.155750  0.818007  ...  2.897853  1.533973  0.941882   \n",
       "3       0.181641 -0.210630  1.007587  ... -0.681879 -1.759520 -0.232496   \n",
       "4       0.123349  0.940386  0.531076  ...  1.554797 -1.125571  0.221238   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "199995 -0.267464  0.343965 -1.044237  ... -1.614024 -0.304913 -0.652910   \n",
       "199996 -0.619971 -1.174315  1.858987  ... -2.601829 -4.318220  1.902997   \n",
       "199997  0.413602 -2.244772  1.099213  ...  0.965286 -2.060376  0.051719   \n",
       "199998  1.051494 -1.053511 -0.798003  ...  0.582595 -0.880470 -0.685185   \n",
       "199999 -2.002757 -1.981669  0.940994  ...  3.131499 -0.470769  0.746012   \n",
       "\n",
       "             194       195       196       197       198       199  200  \n",
       "0      -1.799657  1.713323  2.557487 -0.093983 -0.900870  1.692980  0.0  \n",
       "1      -0.371026  1.504519  0.972150 -0.066232 -0.605402  0.266169  0.0  \n",
       "2      -1.207514 -0.646047 -0.057464 -0.920259 -1.355515  0.844375  0.0  \n",
       "3      -1.399346  0.713252 -1.153311  1.075085 -3.261237  0.879324  0.0  \n",
       "4      -1.169966  0.047702 -0.031349  0.116110 -1.230358 -0.488179  0.0  \n",
       "...          ...       ...       ...       ...       ...       ...  ...  \n",
       "199995 -0.083011 -0.182136 -0.164620  0.341852 -1.212167  0.772141  1.0  \n",
       "199996 -1.239073 -2.094194 -4.741051  0.160564 -3.697052  0.132502  1.0  \n",
       "199997 -4.619251  0.388369 -3.389189  1.176797 -2.018846 -0.324313  1.0  \n",
       "199998 -3.221213  1.341757 -2.525892  0.633955 -3.130941  1.439956  1.0  \n",
       "199999 -1.574813 -0.227272 -0.050823 -2.548302 -2.000663  6.103354  1.0  \n",
       "\n",
       "[200000 rows x 201 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.load(\"D://embedding_matrices//train_lemm_rep_10_10810_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "pd.DataFrame(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training matrix negative marking + replacement + lemmatization with 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.744243</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.748382</td>\n",
       "      <td>2.884386</td>\n",
       "      <td>-1.478211</td>\n",
       "      <td>4.293972</td>\n",
       "      <td>0.781031</td>\n",
       "      <td>4.713445</td>\n",
       "      <td>-2.803378</td>\n",
       "      <td>-0.307988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905514</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>-2.188094</td>\n",
       "      <td>-0.396378</td>\n",
       "      <td>-2.081625</td>\n",
       "      <td>-0.680176</td>\n",
       "      <td>0.250862</td>\n",
       "      <td>-6.093755</td>\n",
       "      <td>-0.568403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.337877</td>\n",
       "      <td>1.794864</td>\n",
       "      <td>-0.772354</td>\n",
       "      <td>0.171728</td>\n",
       "      <td>-0.746612</td>\n",
       "      <td>1.179160</td>\n",
       "      <td>-0.030814</td>\n",
       "      <td>1.151995</td>\n",
       "      <td>-1.632398</td>\n",
       "      <td>0.933478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.278587</td>\n",
       "      <td>0.937628</td>\n",
       "      <td>-0.974902</td>\n",
       "      <td>-1.526594</td>\n",
       "      <td>0.295314</td>\n",
       "      <td>-1.929564</td>\n",
       "      <td>1.297144</td>\n",
       "      <td>-1.645149</td>\n",
       "      <td>1.807026</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.734920</td>\n",
       "      <td>3.841450</td>\n",
       "      <td>2.394832</td>\n",
       "      <td>0.462029</td>\n",
       "      <td>-0.668150</td>\n",
       "      <td>2.605818</td>\n",
       "      <td>-1.497973</td>\n",
       "      <td>-0.048700</td>\n",
       "      <td>-1.210978</td>\n",
       "      <td>2.137351</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.088499</td>\n",
       "      <td>-0.554036</td>\n",
       "      <td>-2.293797</td>\n",
       "      <td>-0.860816</td>\n",
       "      <td>-1.951336</td>\n",
       "      <td>-1.737651</td>\n",
       "      <td>-1.539055</td>\n",
       "      <td>-2.008671</td>\n",
       "      <td>1.857043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.202673</td>\n",
       "      <td>3.920145</td>\n",
       "      <td>0.382464</td>\n",
       "      <td>1.597201</td>\n",
       "      <td>-2.540074</td>\n",
       "      <td>2.941425</td>\n",
       "      <td>0.115403</td>\n",
       "      <td>-0.021783</td>\n",
       "      <td>-1.780407</td>\n",
       "      <td>-0.276521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336696</td>\n",
       "      <td>-0.051184</td>\n",
       "      <td>-2.626957</td>\n",
       "      <td>-1.544261</td>\n",
       "      <td>-2.003611</td>\n",
       "      <td>-2.314967</td>\n",
       "      <td>0.584318</td>\n",
       "      <td>-1.874683</td>\n",
       "      <td>2.465900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.659849</td>\n",
       "      <td>5.294436</td>\n",
       "      <td>0.622598</td>\n",
       "      <td>2.153962</td>\n",
       "      <td>-0.832203</td>\n",
       "      <td>5.753793</td>\n",
       "      <td>0.493405</td>\n",
       "      <td>2.180077</td>\n",
       "      <td>-1.478825</td>\n",
       "      <td>0.909590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023773</td>\n",
       "      <td>-1.022750</td>\n",
       "      <td>-2.165594</td>\n",
       "      <td>-1.227489</td>\n",
       "      <td>-1.262520</td>\n",
       "      <td>-2.813847</td>\n",
       "      <td>-1.513003</td>\n",
       "      <td>-3.685473</td>\n",
       "      <td>1.314285</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2.179512</td>\n",
       "      <td>2.337249</td>\n",
       "      <td>0.554840</td>\n",
       "      <td>0.761305</td>\n",
       "      <td>-0.581756</td>\n",
       "      <td>1.190096</td>\n",
       "      <td>-1.020935</td>\n",
       "      <td>1.113243</td>\n",
       "      <td>-0.941638</td>\n",
       "      <td>-0.821973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911122</td>\n",
       "      <td>0.286562</td>\n",
       "      <td>-1.323795</td>\n",
       "      <td>-1.049783</td>\n",
       "      <td>-1.268288</td>\n",
       "      <td>-0.120509</td>\n",
       "      <td>-1.448560</td>\n",
       "      <td>-1.077077</td>\n",
       "      <td>1.373479</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>6.140747</td>\n",
       "      <td>5.154550</td>\n",
       "      <td>-0.259151</td>\n",
       "      <td>3.896883</td>\n",
       "      <td>-1.231015</td>\n",
       "      <td>7.721708</td>\n",
       "      <td>-2.961629</td>\n",
       "      <td>2.767134</td>\n",
       "      <td>-4.631724</td>\n",
       "      <td>-1.175217</td>\n",
       "      <td>...</td>\n",
       "      <td>3.255477</td>\n",
       "      <td>-0.063861</td>\n",
       "      <td>-2.364963</td>\n",
       "      <td>-3.723600</td>\n",
       "      <td>-3.721205</td>\n",
       "      <td>-6.323569</td>\n",
       "      <td>-0.800615</td>\n",
       "      <td>-3.511398</td>\n",
       "      <td>6.413562</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>3.424637</td>\n",
       "      <td>5.452376</td>\n",
       "      <td>-1.307111</td>\n",
       "      <td>2.183368</td>\n",
       "      <td>-1.058126</td>\n",
       "      <td>3.195762</td>\n",
       "      <td>-0.281791</td>\n",
       "      <td>1.200621</td>\n",
       "      <td>-4.178971</td>\n",
       "      <td>0.207321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404540</td>\n",
       "      <td>-1.143802</td>\n",
       "      <td>-1.939367</td>\n",
       "      <td>-1.689422</td>\n",
       "      <td>-2.694115</td>\n",
       "      <td>-3.479596</td>\n",
       "      <td>-1.821552</td>\n",
       "      <td>-3.310829</td>\n",
       "      <td>3.368952</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2.550781</td>\n",
       "      <td>3.569652</td>\n",
       "      <td>-0.397750</td>\n",
       "      <td>1.644187</td>\n",
       "      <td>-1.520765</td>\n",
       "      <td>4.607465</td>\n",
       "      <td>-1.295443</td>\n",
       "      <td>1.038892</td>\n",
       "      <td>-1.950163</td>\n",
       "      <td>-1.353696</td>\n",
       "      <td>...</td>\n",
       "      <td>1.103851</td>\n",
       "      <td>-0.995495</td>\n",
       "      <td>-2.154025</td>\n",
       "      <td>-1.786899</td>\n",
       "      <td>-2.913442</td>\n",
       "      <td>-4.388548</td>\n",
       "      <td>-0.092228</td>\n",
       "      <td>-3.068846</td>\n",
       "      <td>4.851334</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>4.278479</td>\n",
       "      <td>9.408791</td>\n",
       "      <td>1.312502</td>\n",
       "      <td>4.128036</td>\n",
       "      <td>-0.946330</td>\n",
       "      <td>5.586507</td>\n",
       "      <td>-1.362473</td>\n",
       "      <td>4.500982</td>\n",
       "      <td>-7.175237</td>\n",
       "      <td>-0.516261</td>\n",
       "      <td>...</td>\n",
       "      <td>1.181782</td>\n",
       "      <td>-0.917781</td>\n",
       "      <td>-5.846586</td>\n",
       "      <td>-3.631790</td>\n",
       "      <td>-4.913912</td>\n",
       "      <td>-2.449497</td>\n",
       "      <td>0.141840</td>\n",
       "      <td>-5.861332</td>\n",
       "      <td>6.910228</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0       2.744243  0.064196  0.748382  2.884386 -1.478211  4.293972  0.781031   \n",
       "1       1.337877  1.794864 -0.772354  0.171728 -0.746612  1.179160 -0.030814   \n",
       "2       2.734920  3.841450  2.394832  0.462029 -0.668150  2.605818 -1.497973   \n",
       "3       0.202673  3.920145  0.382464  1.597201 -2.540074  2.941425  0.115403   \n",
       "4       1.659849  5.294436  0.622598  2.153962 -0.832203  5.753793  0.493405   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995  2.179512  2.337249  0.554840  0.761305 -0.581756  1.190096 -1.020935   \n",
       "199996  6.140747  5.154550 -0.259151  3.896883 -1.231015  7.721708 -2.961629   \n",
       "199997  3.424637  5.452376 -1.307111  2.183368 -1.058126  3.195762 -0.281791   \n",
       "199998  2.550781  3.569652 -0.397750  1.644187 -1.520765  4.607465 -1.295443   \n",
       "199999  4.278479  9.408791  1.312502  4.128036 -0.946330  5.586507 -1.362473   \n",
       "\n",
       "             7         8         9    ...       191       192       193  \\\n",
       "0       4.713445 -2.803378 -0.307988  ...  0.905514  0.001194 -2.188094   \n",
       "1       1.151995 -1.632398  0.933478  ...  1.278587  0.937628 -0.974902   \n",
       "2      -0.048700 -1.210978  2.137351  ... -1.088499 -0.554036 -2.293797   \n",
       "3      -0.021783 -1.780407 -0.276521  ...  0.336696 -0.051184 -2.626957   \n",
       "4       2.180077 -1.478825  0.909590  ... -0.023773 -1.022750 -2.165594   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "199995  1.113243 -0.941638 -0.821973  ...  0.911122  0.286562 -1.323795   \n",
       "199996  2.767134 -4.631724 -1.175217  ...  3.255477 -0.063861 -2.364963   \n",
       "199997  1.200621 -4.178971  0.207321  ...  0.404540 -1.143802 -1.939367   \n",
       "199998  1.038892 -1.950163 -1.353696  ...  1.103851 -0.995495 -2.154025   \n",
       "199999  4.500982 -7.175237 -0.516261  ...  1.181782 -0.917781 -5.846586   \n",
       "\n",
       "             194       195       196       197       198       199  200  \n",
       "0      -0.396378 -2.081625 -0.680176  0.250862 -6.093755 -0.568403  0.0  \n",
       "1      -1.526594  0.295314 -1.929564  1.297144 -1.645149  1.807026  0.0  \n",
       "2      -0.860816 -1.951336 -1.737651 -1.539055 -2.008671  1.857043  0.0  \n",
       "3      -1.544261 -2.003611 -2.314967  0.584318 -1.874683  2.465900  0.0  \n",
       "4      -1.227489 -1.262520 -2.813847 -1.513003 -3.685473  1.314285  0.0  \n",
       "...          ...       ...       ...       ...       ...       ...  ...  \n",
       "199995 -1.049783 -1.268288 -0.120509 -1.448560 -1.077077  1.373479  1.0  \n",
       "199996 -3.723600 -3.721205 -6.323569 -0.800615 -3.511398  6.413562  1.0  \n",
       "199997 -1.689422 -2.694115 -3.479596 -1.821552 -3.310829  3.368952  1.0  \n",
       "199998 -1.786899 -2.913442 -4.388548 -0.092228 -3.068846  4.851334  1.0  \n",
       "199999 -3.631790 -4.913912 -2.449497  0.141840 -5.861332  6.910228  1.0  \n",
       "\n",
       "[200000 rows x 201 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.load(\"D://embedding_matrices//train_neg_mark_5_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "pd.DataFrame(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatization + stop words 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr0 = np.load(\"D://embedding_matrices//train_lemm_stop_17543_0.npz\")\n",
    "arr1 = np.load(\"D://embedding_matrices//train_lemm_stop_17543_1.npz\")\n",
    "arr1 = arr1['arr_0']\n",
    "arr0 = arr0['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.444335</td>\n",
       "      <td>-1.318472</td>\n",
       "      <td>0.346028</td>\n",
       "      <td>1.350200</td>\n",
       "      <td>-1.385962</td>\n",
       "      <td>2.767417</td>\n",
       "      <td>1.311231</td>\n",
       "      <td>3.328652</td>\n",
       "      <td>-1.137927</td>\n",
       "      <td>-0.049942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969270</td>\n",
       "      <td>0.406134</td>\n",
       "      <td>-1.840788</td>\n",
       "      <td>1.039715</td>\n",
       "      <td>-0.891630</td>\n",
       "      <td>-0.434733</td>\n",
       "      <td>0.137031</td>\n",
       "      <td>-4.814063</td>\n",
       "      <td>-1.888110</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081177</td>\n",
       "      <td>1.244163</td>\n",
       "      <td>-0.844975</td>\n",
       "      <td>-0.605077</td>\n",
       "      <td>-0.474558</td>\n",
       "      <td>1.599846</td>\n",
       "      <td>0.544017</td>\n",
       "      <td>1.074949</td>\n",
       "      <td>-0.864517</td>\n",
       "      <td>0.913248</td>\n",
       "      <td>...</td>\n",
       "      <td>1.517632</td>\n",
       "      <td>0.870794</td>\n",
       "      <td>-0.962172</td>\n",
       "      <td>-1.082150</td>\n",
       "      <td>0.442742</td>\n",
       "      <td>-1.644324</td>\n",
       "      <td>1.065287</td>\n",
       "      <td>-1.519401</td>\n",
       "      <td>1.735054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.251503</td>\n",
       "      <td>1.373665</td>\n",
       "      <td>0.767569</td>\n",
       "      <td>-1.226704</td>\n",
       "      <td>-0.501497</td>\n",
       "      <td>0.477874</td>\n",
       "      <td>1.980714</td>\n",
       "      <td>-0.500599</td>\n",
       "      <td>0.445129</td>\n",
       "      <td>1.927104</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.019483</td>\n",
       "      <td>0.609414</td>\n",
       "      <td>-1.533673</td>\n",
       "      <td>1.044878</td>\n",
       "      <td>-0.113420</td>\n",
       "      <td>-0.553719</td>\n",
       "      <td>-0.645479</td>\n",
       "      <td>-0.508243</td>\n",
       "      <td>1.294903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.710749</td>\n",
       "      <td>3.078687</td>\n",
       "      <td>0.205875</td>\n",
       "      <td>0.636671</td>\n",
       "      <td>-2.038502</td>\n",
       "      <td>2.830842</td>\n",
       "      <td>1.740228</td>\n",
       "      <td>0.500313</td>\n",
       "      <td>-0.785484</td>\n",
       "      <td>0.367704</td>\n",
       "      <td>...</td>\n",
       "      <td>1.376823</td>\n",
       "      <td>-0.925058</td>\n",
       "      <td>-3.293755</td>\n",
       "      <td>-0.815734</td>\n",
       "      <td>-1.249593</td>\n",
       "      <td>-3.441774</td>\n",
       "      <td>-0.429771</td>\n",
       "      <td>-1.264364</td>\n",
       "      <td>3.197393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.600336</td>\n",
       "      <td>3.964730</td>\n",
       "      <td>0.606346</td>\n",
       "      <td>0.795951</td>\n",
       "      <td>-0.117665</td>\n",
       "      <td>3.840555</td>\n",
       "      <td>1.484611</td>\n",
       "      <td>1.645713</td>\n",
       "      <td>0.064729</td>\n",
       "      <td>1.208043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763729</td>\n",
       "      <td>-1.436267</td>\n",
       "      <td>-0.953035</td>\n",
       "      <td>0.013847</td>\n",
       "      <td>-0.392686</td>\n",
       "      <td>-2.027880</td>\n",
       "      <td>-1.171190</td>\n",
       "      <td>-2.182281</td>\n",
       "      <td>0.264169</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0.937364</td>\n",
       "      <td>1.175528</td>\n",
       "      <td>-0.092796</td>\n",
       "      <td>0.187754</td>\n",
       "      <td>-0.224659</td>\n",
       "      <td>0.531020</td>\n",
       "      <td>-0.210043</td>\n",
       "      <td>0.998402</td>\n",
       "      <td>-0.538856</td>\n",
       "      <td>-0.429381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736004</td>\n",
       "      <td>0.072086</td>\n",
       "      <td>-1.130666</td>\n",
       "      <td>-0.570777</td>\n",
       "      <td>-0.419839</td>\n",
       "      <td>-0.127775</td>\n",
       "      <td>-1.196225</td>\n",
       "      <td>-0.380407</td>\n",
       "      <td>0.288348</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2.717598</td>\n",
       "      <td>2.772437</td>\n",
       "      <td>-0.876427</td>\n",
       "      <td>2.168068</td>\n",
       "      <td>-1.086708</td>\n",
       "      <td>5.918804</td>\n",
       "      <td>-1.076213</td>\n",
       "      <td>1.414478</td>\n",
       "      <td>-2.522229</td>\n",
       "      <td>-0.686380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864480</td>\n",
       "      <td>-1.414399</td>\n",
       "      <td>-2.130669</td>\n",
       "      <td>-0.199844</td>\n",
       "      <td>-2.400389</td>\n",
       "      <td>-5.117435</td>\n",
       "      <td>0.754370</td>\n",
       "      <td>-4.115175</td>\n",
       "      <td>4.927545</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0.596723</td>\n",
       "      <td>3.747364</td>\n",
       "      <td>-1.204093</td>\n",
       "      <td>-0.363936</td>\n",
       "      <td>-0.686662</td>\n",
       "      <td>1.755927</td>\n",
       "      <td>0.968883</td>\n",
       "      <td>1.221958</td>\n",
       "      <td>-1.282437</td>\n",
       "      <td>0.619975</td>\n",
       "      <td>...</td>\n",
       "      <td>1.583072</td>\n",
       "      <td>0.699452</td>\n",
       "      <td>-1.804382</td>\n",
       "      <td>-1.961779</td>\n",
       "      <td>-0.886282</td>\n",
       "      <td>-2.191551</td>\n",
       "      <td>-1.388790</td>\n",
       "      <td>-0.575552</td>\n",
       "      <td>1.803209</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2.157615</td>\n",
       "      <td>1.785706</td>\n",
       "      <td>0.332653</td>\n",
       "      <td>0.942408</td>\n",
       "      <td>-1.691892</td>\n",
       "      <td>1.855060</td>\n",
       "      <td>0.552634</td>\n",
       "      <td>1.040187</td>\n",
       "      <td>-0.672752</td>\n",
       "      <td>-0.130366</td>\n",
       "      <td>...</td>\n",
       "      <td>1.160739</td>\n",
       "      <td>-0.854388</td>\n",
       "      <td>-1.427779</td>\n",
       "      <td>-0.985142</td>\n",
       "      <td>-1.888865</td>\n",
       "      <td>-3.311204</td>\n",
       "      <td>-0.499471</td>\n",
       "      <td>-1.765131</td>\n",
       "      <td>3.507219</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>1.416145</td>\n",
       "      <td>3.955163</td>\n",
       "      <td>0.465564</td>\n",
       "      <td>1.325698</td>\n",
       "      <td>-0.289621</td>\n",
       "      <td>1.550797</td>\n",
       "      <td>1.960828</td>\n",
       "      <td>2.620017</td>\n",
       "      <td>-2.083356</td>\n",
       "      <td>0.265323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.585904</td>\n",
       "      <td>-0.260417</td>\n",
       "      <td>-2.902417</td>\n",
       "      <td>-0.455114</td>\n",
       "      <td>-2.569437</td>\n",
       "      <td>-0.832484</td>\n",
       "      <td>-0.363861</td>\n",
       "      <td>-2.381242</td>\n",
       "      <td>2.399019</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0       1.444335 -1.318472  0.346028  1.350200 -1.385962  2.767417  1.311231   \n",
       "1       1.081177  1.244163 -0.844975 -0.605077 -0.474558  1.599846  0.544017   \n",
       "2       0.251503  1.373665  0.767569 -1.226704 -0.501497  0.477874  1.980714   \n",
       "3       0.710749  3.078687  0.205875  0.636671 -2.038502  2.830842  1.740228   \n",
       "4       0.600336  3.964730  0.606346  0.795951 -0.117665  3.840555  1.484611   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995  0.937364  1.175528 -0.092796  0.187754 -0.224659  0.531020 -0.210043   \n",
       "199996  2.717598  2.772437 -0.876427  2.168068 -1.086708  5.918804 -1.076213   \n",
       "199997  0.596723  3.747364 -1.204093 -0.363936 -0.686662  1.755927  0.968883   \n",
       "199998  2.157615  1.785706  0.332653  0.942408 -1.691892  1.855060  0.552634   \n",
       "199999  1.416145  3.955163  0.465564  1.325698 -0.289621  1.550797  1.960828   \n",
       "\n",
       "             7         8         9    ...       191       192       193  \\\n",
       "0       3.328652 -1.137927 -0.049942  ...  0.969270  0.406134 -1.840788   \n",
       "1       1.074949 -0.864517  0.913248  ...  1.517632  0.870794 -0.962172   \n",
       "2      -0.500599  0.445129  1.927104  ... -2.019483  0.609414 -1.533673   \n",
       "3       0.500313 -0.785484  0.367704  ...  1.376823 -0.925058 -3.293755   \n",
       "4       1.645713  0.064729  1.208043  ...  0.763729 -1.436267 -0.953035   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "199995  0.998402 -0.538856 -0.429381  ...  0.736004  0.072086 -1.130666   \n",
       "199996  1.414478 -2.522229 -0.686380  ...  0.864480 -1.414399 -2.130669   \n",
       "199997  1.221958 -1.282437  0.619975  ...  1.583072  0.699452 -1.804382   \n",
       "199998  1.040187 -0.672752 -0.130366  ...  1.160739 -0.854388 -1.427779   \n",
       "199999  2.620017 -2.083356  0.265323  ... -0.585904 -0.260417 -2.902417   \n",
       "\n",
       "             194       195       196       197       198       199  200  \n",
       "0       1.039715 -0.891630 -0.434733  0.137031 -4.814063 -1.888110  0.0  \n",
       "1      -1.082150  0.442742 -1.644324  1.065287 -1.519401  1.735054  0.0  \n",
       "2       1.044878 -0.113420 -0.553719 -0.645479 -0.508243  1.294903  0.0  \n",
       "3      -0.815734 -1.249593 -3.441774 -0.429771 -1.264364  3.197393  0.0  \n",
       "4       0.013847 -0.392686 -2.027880 -1.171190 -2.182281  0.264169  0.0  \n",
       "...          ...       ...       ...       ...       ...       ...  ...  \n",
       "199995 -0.570777 -0.419839 -0.127775 -1.196225 -0.380407  0.288348  1.0  \n",
       "199996 -0.199844 -2.400389 -5.117435  0.754370 -4.115175  4.927545  1.0  \n",
       "199997 -1.961779 -0.886282 -2.191551 -1.388790 -0.575552  1.803209  1.0  \n",
       "199998 -0.985142 -1.888865 -3.311204 -0.499471 -1.765131  3.507219  1.0  \n",
       "199999 -0.455114 -2.569437 -0.832484 -0.363861 -2.381242  2.399019  1.0  \n",
       "\n",
       "[200000 rows x 201 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training matrix for full vocabulary 10 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  train_neg.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n",
      "Working on  train_neg.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"vocabulary_10_full_12656.pkl\", \"rb\") as f:\n",
    "    voc = pickle.load(f)\n",
    "with open(\"cooc_10_full_12656.pkl\", \"rb\") as f:\n",
    "    cooc = pickle.load(f)\n",
    "    \n",
    "emb = EmbeddingBase(embedding_name = \"emb_10_full_12656.npz\",\n",
    "                 embedding_dimension = 200,\n",
    "                 vocabulary = voc,\n",
    "                 cooc = cooc,\n",
    "                 load = True)\n",
    "\n",
    "mat1 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg.txt\",\"train_pos.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          sentence_dimesion = 200,\n",
    "                          output_location = \"training_matrices\\\\train_10_full_12656_1\")\n",
    "\n",
    "mat2 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg.txt\",\"train_pos.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          aggregation_fun=sentence_embedding.no_embeddings,\n",
    "                          sentence_dimesion = 100,\n",
    "                          output_location = \"training_matrices\\\\train_10_full_12656_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training matrix for full vocabulary 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  train_neg.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n",
      "Working on  train_neg.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"dictionary_full_21175.pkl\", \"rb\") as f:\n",
    "    voc = pickle.load(f)\n",
    "with open(\"cooc_full_21175.pkl\", \"rb\") as f:\n",
    "    cooc = pickle.load(f)\n",
    "    \n",
    "emb = EmbeddingBase(embedding_name = \"emb_full_21175.npz\",\n",
    "                 embedding_dimension = 200,\n",
    "                 vocabulary = voc,\n",
    "                 cooc = cooc,\n",
    "                 load = True)\n",
    "\n",
    "mat1 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg.txt\",\"train_pos.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          sentence_dimesion = 200,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_full_21175_1\")\n",
    "\n",
    "mat2 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg.txt\",\"train_pos.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          aggregation_fun=sentence_embedding.no_embeddings,\n",
    "                          sentence_dimesion = 100,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_full_21175_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training matrix for lemm 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  train_neg_lemmatized.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_lemmatized.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n",
      "Working on  train_neg_lemmatized.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_lemmatized.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"dictionary_lemm_18082.pkl\", \"rb\") as f:\n",
    "    voc = pickle.load(f)\n",
    "with open(\"cooc_lemm_18082.pkl\", \"rb\") as f:\n",
    "    cooc = pickle.load(f)\n",
    "    \n",
    "emb = EmbeddingBase(embedding_name = \"emb_lemm_18082.npz\",\n",
    "                 embedding_dimension = 200,\n",
    "                 vocabulary = voc,\n",
    "                 cooc = cooc,\n",
    "                 load = True)\n",
    "\n",
    "mat1 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_lemmatized.txt\",\"train_pos_lemmatized.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          sentence_dimesion = 200,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_lemm_18082_1\")\n",
    "\n",
    "mat2 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_lemmatized.txt\",\"train_pos_lemmatized.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          aggregation_fun=sentence_embedding.no_embeddings,\n",
    "                          sentence_dimesion = 100,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_lemm_18082_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training matrix for lemmatized + stopwords 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  train_neg_lemmatized.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_lemmatized.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n",
      "Working on  train_neg_lemmatized.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_lemmatized.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"dict_lemm_stop_17543.pkl\", \"rb\") as f:\n",
    "    voc = pickle.load(f)\n",
    "with open(\"cooc_lemm_stop_17543.pkl\", \"rb\") as f:\n",
    "    cooc = pickle.load(f)\n",
    "    \n",
    "emb = EmbeddingBase(embedding_name = \"emb_lemm_stop_17543.npz\",\n",
    "                 embedding_dimension = 200,\n",
    "                 vocabulary = voc,\n",
    "                 cooc = cooc,\n",
    "                 load = True)\n",
    "\n",
    "mat1 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_lemmatized.txt\",\"train_pos_lemmatized.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          sentence_dimesion = 200,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_lemm_stop_17543_1\")\n",
    "\n",
    "mat2 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_lemmatized.txt\",\"train_pos_lemmatized.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          aggregation_fun=sentence_embedding.no_embeddings,\n",
    "                          sentence_dimesion = 100,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_lemm_stop_17543_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training matrix for lemmatized + replacement5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab_lemm_rep_17891_5.pkl\", \"rb\") as f:\n",
    "    voc = pickle.load(f)\n",
    "with open(\"cooc_lemm_rep_17891_5.pkl\", \"rb\") as f:\n",
    "    cooc = pickle.load(f)\n",
    "    \n",
    "emb = EmbeddingBase(embedding_name = \"emb_lemm_rep_17891_5.npz\",\n",
    "                 embedding_dimension = 200,\n",
    "                 vocabulary = voc,\n",
    "                 cooc = cooc,\n",
    "                 load = True)\n",
    "\n",
    "mat1 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_lemm_repl_no_pickle.txt\",\"train_pos_lemm_repl_no_pickle.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          sentence_dimesion = 200,\n",
    "                          output_location = \"training_matrices\\\\train_lemm_rep_17891_5_1\")\n",
    "\n",
    "mat2 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_lemm_repl_no_pickle.txt\",\"train_pos_lemm_repl_no_pickle.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          aggregation_fun=sentence_embedding.no_embeddings,\n",
    "                          sentence_dimesion = 100,\n",
    "                          output_location = \"training_matrices\\\\train_lemm_rep_17891_5_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training matrix for lemmatized + stopwords 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  train_neg_lemm_repl_no_pickle.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_lemm_repl_no_pickle.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n",
      "Working on  train_neg_lemm_repl_no_pickle.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_lemm_repl_no_pickle.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"vocab_lemm_rep_10_10810.pkl\", \"rb\") as f:\n",
    "    voc = pickle.load(f)\n",
    "with open(\"cooc_lemm_rep_10_10810.pkl\", \"rb\") as f:\n",
    "    cooc = pickle.load(f)\n",
    "    \n",
    "emb = EmbeddingBase(embedding_name = \"emb_lemm_rep_10_10810.npz\",\n",
    "                 embedding_dimension = 200,\n",
    "                 vocabulary = voc,\n",
    "                 cooc = cooc,\n",
    "                 load = True)\n",
    "\n",
    "mat1 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_lemm_repl_no_pickle.txt\",\"train_pos_lemm_repl_no_pickle.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          sentence_dimesion = 200,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_lemm_rep_10_10810_1\")\n",
    "\n",
    "mat2 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_lemm_repl_no_pickle.txt\",\"train_pos_lemm_repl_no_pickle.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          aggregation_fun=sentence_embedding.no_embeddings,\n",
    "                          sentence_dimesion = 100,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_lemm_rep_10_10810_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training matrix for negation marking + lemmatized + repl 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  train_neg_negation_mark.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_negation_mark.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n",
      "Working on  train_neg_negation_mark.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_negation_mark.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"dictionary_negation_mark_5.pkl\", \"rb\") as f:\n",
    "    voc = pickle.load(f)\n",
    "with open(\"cooc__negation_mark_5.pkl\", \"rb\") as f:\n",
    "    cooc = pickle.load(f)\n",
    "    \n",
    "emb = EmbeddingBase(embedding_name = \"emb_negation_5.npz\",\n",
    "                 embedding_dimension = 200,\n",
    "                 vocabulary = voc,\n",
    "                 cooc = cooc,\n",
    "                 load = True)\n",
    "\n",
    "mat1 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_negation_mark.txt\",\"train_pos_negation_mark.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          sentence_dimesion = 200,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_neg_mark_5_1\")\n",
    "\n",
    "mat2 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_negation_mark.txt\",\"train_pos_negation_mark.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          aggregation_fun=sentence_embedding.no_embeddings,\n",
    "                          sentence_dimesion = 100,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_neg_mark_5_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building training matrix for lemmatized + stopwords 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on  train_neg_negation_mark.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_negation_mark.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n",
      "Working on  train_neg_negation_mark.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Working on  train_pos_negation_mark.txt\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Number of lines read: 200000\n"
     ]
    }
   ],
   "source": [
    "with open(\"dictionary_negation_mark_10.pkl\", \"rb\") as f:\n",
    "    voc = pickle.load(f)\n",
    "with open(\"cooc__negation_mark_10.pkl\", \"rb\") as f:\n",
    "    cooc = pickle.load(f)\n",
    "    \n",
    "emb = EmbeddingBase(embedding_name = \"emb_negation_10.npz\",\n",
    "                 embedding_dimension = 200,\n",
    "                 vocabulary = voc,\n",
    "                 cooc = cooc,\n",
    "                 load = True)\n",
    "\n",
    "mat1 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_negation_mark.txt\",\"train_pos_negation_mark.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          sentence_dimesion = 200,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_neg_mark_10_1\")\n",
    "\n",
    "mat2 = pipe.build_training_matrix(label = True,\n",
    "                          embedding = emb,\n",
    "                          input_files=[\"train_neg_negation_mark.txt\",\"train_pos_negation_mark.txt\"],\n",
    "                          label_values=None,\n",
    "                          input_entries=200000,\n",
    "                          aggregation_fun=sentence_embedding.no_embeddings,\n",
    "                          sentence_dimesion = 100,\n",
    "                          output_location = \"D:\\\\embedding_matrices\\\\train_neg_mark_10_0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
